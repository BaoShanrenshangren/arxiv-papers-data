{
  "id": "2512.18004v1",
  "title": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
  "authors": [
    "Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya"
  ],
  "abstract": "arXiv:2512.18004v1 Announce Type: cross \nAbstract: Handwritten text recognition (HTR) and machine translation continue to pose significant challenges, particularly for low-resource languages like Marathi, which lack large digitized corpora and exhibit high variability in handwriting styles. The conventional approach to address this involves a two-stage pipeline: an OCR system extracts text from handwritten images, which is then translated into the target language using a machine translation model. In this work, we explore and compare the performance of traditional OCR-MT pipelines with Vision Large Language Models that aim to unify these stages and directly translate handwritten text images in a single, end-to-end step. Our motivation is grounded in the urgent need for scalable, accurate translation systems to digitize legal records such as FIRs, charge sheets, and witness statements in India's district and high courts. We evaluate both approaches on a curated dataset of handwritten Marathi legal documents, with the goal of enabling efficient legal document processing, even in low-resource environments. Our findings offer actionable insights toward building robust, edge-deployable solutions that enhance access to legal information for non-native speakers and legal professionals alike.",
  "url": "https://arxiv.org/abs/2512.18004",
  "html_url": "https://arxiv.org/html/2512.18004v1",
  "html_content": "",
  "preview_text": "arXiv:2512.18004v1 Announce Type: cross \nAbstract: Handwritten text recognition (HTR) and machine translation continue to pose significant challenges, particularly for low-resource languages like Marathi, which lack large digitized corpora and exhibit high variability in handwriting styles. The conventional approach to address this involves a two-stage pipeline: an OCR system extracts text from handwritten images, which is then translated into the target language using a machine translation model. In this work, we explore and compare the performance of traditional OCR-MT pipelines with Vision Large Language Models that aim to unify these stages and directly translate handwritten text images in a single, end-to-end step. Our motivation is grounded in the urgent need for scalable, accurate translation systems to digitize legal records such as FIRs, charge sheets, and witness statements in India's district and high courts. We evaluate both approaches on a curated dataset of handwritten Marathi legal documents, with the goal of enabling efficient legal document processing, even in low-resource environments. Our findings offer actionable insights toward building robust, edge-deployable solutions that enhance access to legal information for non-native speakers and legal professionals alike.",
  "is_relevant": false,
  "relevance_score": 2.0,
  "extracted_keywords": [
    "OCR",
    "Vision-Language Models",
    "handwritten text recognition",
    "machine translation",
    "low-resource languages",
    "legal documents"
  ],
  "one_line_summary": "该论文探讨了使用OCR和视觉语言模型进行手写法律文档翻译的方法，以解决低资源语言如马拉地语的挑战，但与关键词中的视频扩散、多模态生成、高效LLM和扩散模型等技术领域相关性较低。",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "published_date": "Tue, 23 Dec 2025 00:00:00 -0500",
  "created_at": "2025-12-23T15:47:58.334332",
  "updated_at": "2025-12-23T15:47:58.334349"
}