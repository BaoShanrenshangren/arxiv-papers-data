{
  "id": "2512.19396v1",
  "title": "EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration",
  "authors": [
    "Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang"
  ],
  "abstract": "arXiv:2512.19396v1 Announce Type: new \nAbstract: Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital ''amnesia'' results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable ''memories''. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent's reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.",
  "url": "https://arxiv.org/abs/2512.19396",
  "html_url": "https://arxiv.org/html/2512.19396v1",
  "html_content": "",
  "preview_text": "arXiv:2512.19396v1 Announce Type: new \nAbstract: Contemporary GUI agents, while increasingly capable due to advances in Large Vision-Language Models (VLMs), often operate with a critical limitation: they treat each task in isolation, lacking a mechanism to systematically learn from past successes. This digital ''amnesia'' results in sub-optimal performance, repeated errors, and poor generalization to novel challenges. To bridge this gap, we introduce EchoTrail-GUI, a novel framework designed to mimic human-like experiential learning by equipping agents with a dynamic, accessible memory. Our framework operates in three distinct stages. First, during Experience Exploration, an agent autonomously interacts with GUI environments to build a curated database of successful task trajectories, validated by a reward model. Crucially, the entire knowledge base construction is thus fully automated, requiring no human supervision. Second, in the Memory Injection stage, upon receiving a new task, our system efficiently retrieves the most relevant past trajectories to serve as actionable ''memories''. Finally, during GUI Task Inference, these memories are injected as in-context guidance to inform the agent's reasoning and decision-making process. We demonstrate the efficacy of our approach on benchmarks including Android World and AndroidLab. The results show that EchoTrail-GUI significantly improves the task success rate and operational efficiency of baseline agents, validating the power of structured memory in creating more robust and intelligent GUI automation.",
  "is_relevant": false,
  "relevance_score": 1.0,
  "extracted_keywords": [
    "GUI agents",
    "memory framework",
    "experiential learning",
    "automated knowledge base",
    "task trajectories",
    "in-context guidance"
  ],
  "one_line_summary": "这篇论文提出了一种通过批评引导的自探索为GUI代理构建可操作记忆的框架，以提升任务成功率和效率，与关键词中的视频扩散、多模态生成等主题无关。",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "published_date": "Tue, 23 Dec 2025 00:00:00 -0500",
  "created_at": "2025-12-23T15:47:46.213416",
  "updated_at": "2025-12-23T15:47:46.213429"
}