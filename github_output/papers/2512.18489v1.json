{
  "id": "2512.18489v1",
  "title": "Large Language Models as Discounted Bayesian Filters",
  "authors": [
    "Jensen Zhang, Jing Yang, Keze Wang"
  ],
  "abstract": "arXiv:2512.18489v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate strong few-shot generalization through in-context learning, yet their reasoning in dynamic and stochastic environments remains opaque. Prior studies mainly focus on static tasks and overlook the online adaptation required when beliefs must be continuously updated, which is a key capability for LLMs acting as world models or agents. We introduce a Bayesian filtering framework to evaluate online inference in LLMs. Our probabilistic probe suite spans both multivariate discrete distributions, such as dice rolls, and continuous distributions, such as Gaussian processes, where ground-truth parameters shift over time. We find that while LLM belief updates resemble Bayesian posteriors, they are more accurately characterized by an exponential forgetting filter with a model-specific discount factor smaller than one. This reveals systematic discounting of older evidence that varies significantly across model architectures. Although inherent priors are often miscalibrated, the updating mechanism itself remains structured and principled. We further validate these findings in a simulated agent task and propose prompting strategies that effectively recalibrate priors with minimal computational cost.",
  "url": "https://arxiv.org/abs/2512.18489",
  "html_url": "https://arxiv.org/html/2512.18489v1",
  "html_content": "",
  "preview_text": "arXiv:2512.18489v1 Announce Type: new \nAbstract: Large Language Models (LLMs) demonstrate strong few-shot generalization through in-context learning, yet their reasoning in dynamic and stochastic environments remains opaque. Prior studies mainly focus on static tasks and overlook the online adaptation required when beliefs must be continuously updated, which is a key capability for LLMs acting as world models or agents. We introduce a Bayesian filtering framework to evaluate online inference in LLMs. Our probabilistic probe suite spans both multivariate discrete distributions, such as dice rolls, and continuous distributions, such as Gaussian processes, where ground-truth parameters shift over time. We find that while LLM belief updates resemble Bayesian posteriors, they are more accurately characterized by an exponential forgetting filter with a model-specific discount factor smaller than one. This reveals systematic discounting of older evidence that varies significantly across model architectures. Although inherent priors are often miscalibrated, the updating mechanism itself remains structured and principled. We further validate these findings in a simulated agent task and propose prompting strategies that effectively recalibrate priors with minimal computational cost.",
  "is_relevant": false,
  "relevance_score": 2.0,
  "extracted_keywords": [
    "LLM",
    "Bayesian filtering",
    "online inference",
    "discount factor",
    "probabilistic probe"
  ],
  "one_line_summary": "该论文提出一个贝叶斯过滤框架来评估LLM在动态环境中的在线推理能力，发现其信念更新类似于指数遗忘过滤器，与视频扩散或多模态生成等关键词相关性较低。",
  "detailed_summary": "",
  "qa_pairs": [],
  "is_hidden": false,
  "is_starred": false,
  "published_date": "Tue, 23 Dec 2025 00:00:00 -0500",
  "created_at": "2025-12-23T15:44:33.711595",
  "updated_at": "2025-12-23T15:44:33.711608"
}